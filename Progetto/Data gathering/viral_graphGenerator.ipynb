{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee7a2ef-5811-4140-9916-c2651fb8b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f48f45be-9b7c-4a79-9e93-e701e9def701",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c34ada5-3e6f-4f24-9d59-8071d998a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = list()\n",
    "with open('viral.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        people.append(row)\n",
    "\n",
    "#questo è il mio dataset a ogni indice corrisponde una lista di codici ISRC (30 per playlist tranne in rari casi)\n",
    "dataset = list()\n",
    "\n",
    "#prendo il link della playlist dalla lista people creata prima\n",
    "#dal link estraggo l'id della playlist\n",
    "#dall'id della playlist estraggo tutti i brani da ogni brano estraggo il codice ISRC\n",
    "for person in people:\n",
    "\n",
    "    #prendo il link della playlist da person \n",
    "    playlist = spotify.playlist(person[\"Link\"])\n",
    "    #dal link estraggo l'id della playlist\n",
    "    songs = spotify.playlist_items(playlist[\"id\"]) \n",
    "\n",
    "    #insieme ausiliario in cui metto tutti gli ISRC di una singola playlist\n",
    "    aux = set()\n",
    "\n",
    "    #estraggo da ogni canzone il codice ISRC e lo inserisco nell'insieme aux\n",
    "    for i in range (len(songs[\"items\"])):\n",
    "        aux.add(songs[\"items\"][i][\"track\"][\"uri\"])\n",
    "        #aux.add(songs[\"items\"][i][\"track\"][\"external_ids\"][\"isrc\"])\n",
    "    \n",
    "    #appendo al mio dataset gli ISRC estratti per ogni playlist\n",
    "    #indice 0 avrò codici ISRC della playlist dell'utente 0 che in realtà è gia \n",
    "    #relazionato con il suo nome\n",
    "    dataset.append(aux)\n",
    "\n",
    "#----FINE----API-SPOTIFY----FINE----\n",
    "\n",
    "#n risulta uguale alla lunghezza del nostro dataset quindi al numero di utenti\n",
    "#per il quali siamo andati ad estrarre le canzoni dalla playlist\n",
    "n = len(dataset)\n",
    "\n",
    "centrality = {}\n",
    "for x in range (1,n) : \n",
    "        affinity = len(dataset[0].intersection(dataset[x]))\n",
    "        centrality[people[x][\"Name\"]] = affinity\n",
    "\n",
    "#print(centrality)\n",
    "\n",
    "centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "header = ['Paese', 'Centralità']\n",
    "with open('viral-centrality.csv', 'w+', newline='', encoding='utf-16') as file:\n",
    "    #writer = csv.DictWriter(file,fieldnames=[\"Paese\",\"Centralità\"])\n",
    "    writer = csv.writer(file)\n",
    "    #scrive Paese Centralità nel file csv come intestazione\n",
    "    writer.writerow(header)\n",
    "    #scrive id affiancato da nome nel file\n",
    "    for i in range (len(centrality)) :\n",
    "        writer.writerow(centrality[i])\n",
    "\n",
    "grafo = nx.Graph()\n",
    "\n",
    "for i in range (1,len(people)) :\n",
    "        #writer.writerow({\"Id\":i,\"Label\":people[i][\"Name\"]})\n",
    "        grafo.add_node(i,label=people[i][\"Name\"],latitudine=float(people[i][\"latitudine\"]),longitudine=float(people[i][\"longitudine\"]))\n",
    "\n",
    "#dato che trattiamo le canzoni estratte come insiemi a coppie di utenti\n",
    "#intersechiamo questi insiemi ed estraiamo il numero di elementi\n",
    "#ovvero le canzoni che hanno in comune ovvero il loro grado di affinità\n",
    "for x in range (1,n) : \n",
    "    for y in range (x+1,n) :\n",
    "        #intersezione degli insiemi di canzoni tra utenti\n",
    "        affinity = len(dataset[x].intersection(dataset[y]))\n",
    "\n",
    "        #se l'intersezione non è vuota vuol dire che ho un link valido\n",
    "        #pertanto aggiungo gli id degli utenti e il numero di canzoni\n",
    "        #che hanno in comune\n",
    "        if affinity :\n",
    "            grafo.add_edge(x,y,weight=affinity)\n",
    "            #edges.append({\"Source\":x, \"Target\":y, \"Weight\":affinity})\n",
    "nx.write_gexf(grafo,'viral08.gexf')\n",
    "with open('viral08.pkl', 'wb') as f:\n",
    "    pickle.dump(grafo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdcd5f0-930a-4cc1-aae7-b4e6fc7b4b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
