{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca148064-85ff-442f-993e-d2c82ee2a954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e3753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d1e63a3-c67b-43ef-860e-ecec12677d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m csv_reader:\n\u001b[1;32m---> 43\u001b[0m     s\u001b[38;5;241m=\u001b[39m\u001b[43mline\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m     s\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m     s\u001b[38;5;241m=\u001b[39ms\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from unittest import result\n",
    "from joblib import PrintTime\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Data preprocessing and trasformation (ETL)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, FunctionTransformer, Binarizer, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml, load_iris, make_moons, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Math and Stat modules\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from random import choice\n",
    "\n",
    "# Supervised Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold, StratifiedKFold, RepeatedKFold, ShuffleSplit, StratifiedShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset_link_prediction = pd.read_csv('machine-global-mergedfix2 - Copia.csv')\n",
    "\n",
    "generi = set()\n",
    "with open('machine-global-mergedfix2 - Copia.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        s=line[3].replace(\"[\",\"\")\n",
    "        s=s.replace(\"]\",\"\")\n",
    "        s=s.replace(\"'\",\"\")\n",
    "        genres = s.split(\",\")\n",
    "        for genre in genres:\n",
    "            if len(genre) > 0 and genre[0] == \" \":\n",
    "                genre = genre[1:]\n",
    "            generi.add(genre)\n",
    "\n",
    "for genere in generi:\n",
    "    dataset_link_prediction[genere] = 0\n",
    "\n",
    "#print(dataset_link_prediction)\n",
    "\n",
    "riga = -1\n",
    "with open('machine-global-mergedfix2 - Copia.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        if line[0] != 'paese':\n",
    "            riga = riga+1\n",
    "            s=line[3].replace(\"[\",\"\")\n",
    "            s=s.replace(\"]\",\"\")\n",
    "            s=s.replace(\"'\",\"\")\n",
    "            genres = s.split(\",\")\n",
    "            for genre in genres:\n",
    "                if len(genre) > 0 and genre[0] == \" \":\n",
    "                    genre = genre[1:]\n",
    "                dataset_link_prediction.loc[riga,genre] = 1\n",
    "\n",
    "X = dataset_link_prediction.iloc[:, 4:] #feature matrix\n",
    "y = dataset_link_prediction['paese'] # label\n",
    "\n",
    "#print(dataset_link_prediction.loc[1,'art rock'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train_minmax, y_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "y_predicted_lr = clf_logreg.predict(X_test_minmax)\n",
    "\n",
    "print(classification_report(y_test,y_predicted_lr))\n",
    "\n",
    "print(accuracy_score(y_test, y_predicted_lr))\n",
    "#print(len(set(y_test) - set(y_predicted_lr)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ffed6-47ec-48fc-9e7a-5f146c5ef9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
