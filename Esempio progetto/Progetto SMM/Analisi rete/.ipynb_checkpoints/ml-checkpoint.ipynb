{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "702ef5c3-47a9-4740-999f-37cf002b6347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  paese          isrc  \\\n",
      "0                                        Arabia_Saudita  USUG12401028   \n",
      "1                                        Arabia_Saudita  USA2P2251865   \n",
      "2     Arabia_Saudita,GBKPL2205058,spotify:track:3qhl...           NaN   \n",
      "3                                        Arabia_Saudita  QZJ842400387   \n",
      "4                                        Arabia_Saudita  USUG12401029   \n",
      "...                                                 ...           ...   \n",
      "6980                                            Vietnam  USUM72403305   \n",
      "6981  Vietnam,SGUM72301146,spotify:track:1o6cYDMHvKO...           NaN   \n",
      "6982                                            Vietnam  VNA092200688   \n",
      "6983  Vietnam,VNA092300389,spotify:track:1K0HQ30Wc11...           NaN   \n",
      "6984  Vietnam,VNA092300389,spotify:track:1K0HQ30Wc11...           NaN   \n",
      "\n",
      "                                       uri     genres  danceability  energy  \\\n",
      "0     spotify:track:2OzhQlSqBEmt7hmkYxfT6m    ['pop']         0.675   0.397   \n",
      "1     spotify:track:3Ua0m0YmEjrMi9XErKcNiR  ['k-pop']         0.629   0.733   \n",
      "2                                      NaN        NaN           NaN     NaN   \n",
      "3     spotify:track:2GxrNKugF82CnoRFbQfzPf         []         0.599   0.946   \n",
      "4     spotify:track:3NMrVbIVWT3fPXBj0rNDKG    ['pop']         0.595   0.421   \n",
      "...                                    ...        ...           ...     ...   \n",
      "6980  spotify:track:2qSkIjg1o9h3YT9RAgYN75    ['pop']         0.701   0.760   \n",
      "6981                                   NaN        NaN           NaN     NaN   \n",
      "6982  spotify:track:5PLjpBivzvuaIIqqkQgnRK  ['v-pop']         0.547   0.420   \n",
      "6983                                   NaN        NaN           NaN     NaN   \n",
      "6984                                   NaN        NaN           NaN     NaN   \n",
      "\n",
      "      speechiness  acousticness  instrumentalness  valence  \\\n",
      "0          0.0245      0.499000          0.000006    0.319   \n",
      "1          0.0419      0.002500          0.000000    0.362   \n",
      "2             NaN           NaN               NaN      NaN   \n",
      "3          0.0447      0.000938          0.010600    0.747   \n",
      "4          0.0261      0.051800          0.000002    0.261   \n",
      "...           ...           ...               ...      ...   \n",
      "6980       0.0285      0.107000          0.000065    0.690   \n",
      "6981          NaN           NaN               NaN      NaN   \n",
      "6982       0.2790      0.886000          0.000735    0.547   \n",
      "6983          NaN           NaN               NaN      NaN   \n",
      "6984          NaN           NaN               NaN      NaN   \n",
      "\n",
      "        tempo;;;;;;;;;;;;;;;;;  \n",
      "0      95.988;;;;;;;;;;;;;;;;;  \n",
      "1     120.001;;;;;;;;;;;;;;;;;  \n",
      "2                          NaN  \n",
      "3     151.647;;;;;;;;;;;;;;;;;  \n",
      "4     110.305;;;;;;;;;;;;;;;;;  \n",
      "...                        ...  \n",
      "6980  103.969;;;;;;;;;;;;;;;;;  \n",
      "6981                       NaN  \n",
      "6982   173.98;;;;;;;;;;;;;;;;;  \n",
      "6983                       NaN  \n",
      "6984                       NaN  \n",
      "\n",
      "[6985 rows x 11 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset_ok = pd.read_csv(\\'bello.csv\\')\\nprint(dataset_link_prediction)\\n#print(dataset_ok)\\n\\n\\ngeneri = set()\\nwith open(\\'output2.csv\\', \\'r\\') as f:\\n    csv_reader = csv.reader(f)\\n    for line in csv_reader:\\n        s=line[3].replace(\"[\",\"\")\\n        s=s.replace(\"]\",\"\")\\n        s=s.replace(\"\\'\",\"\")\\n        genres = s.split(\",\")\\n        for genre in genres:\\n            if len(genre) > 0 and genre[0] == \" \":\\n                genre = genre[1:]\\n            generi.add(genre)\\n\\nfor genere in generi:\\n    dataset_link_prediction[genere] = 0\\n\\nprint(dataset_link_prediction)\\n\\nriga = -1\\nwith open(\\'output2.csv\\', \\'r\\') as f:\\n    csv_reader = csv.reader(f)\\n    for line in csv_reader:\\n        if line[0] != \\'paese\\':\\n            riga = riga+1\\n            s=line[3].replace(\"[\",\"\")\\n            s=s.replace(\"]\",\"\")\\n            s=s.replace(\"\\'\",\"\")\\n            genres = s.split(\",\")\\n            for genre in genres:\\n                if len(genre) > 0 and genre[0] == \" \":\\n                    genre = genre[1:]\\n                dataset_link_prediction.loc[riga,genre] = 1\\n\\nX = dataset_link_prediction.iloc[:, 4:] #feature matrix\\ny = dataset_link_prediction[\\'paese\\'] # label\\n\\n#print(dataset_link_prediction.loc[1,\\'art rock\\'])\\n\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\\n\\n\\nmin_max_scaler = MinMaxScaler()\\nX_train_minmax = min_max_scaler.fit_transform(X_train)\\n\\nclf_logreg = LogisticRegression()\\nclf_logreg.fit(X_train_minmax, y_train)\\nX_test_minmax = min_max_scaler.transform(X_test)\\ny_predicted_lr = clf_logreg.predict(X_test_minmax)\\n\\nprint(classification_report(y_test,y_predicted_lr))\\n\\nprint(accuracy_score(y_test, y_predicted_lr))\\n#print(len(set(y_test) - set(y_predicted_lr)))\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from unittest import result\n",
    "from joblib import PrintTime\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Data preprocessing and trasformation (ETL)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler, FunctionTransformer, Binarizer, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml, load_iris, make_moons, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Math and Stat modules\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "from random import choice\n",
    "\n",
    "# Supervised Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold, StratifiedKFold, RepeatedKFold, ShuffleSplit, StratifiedShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, accuracy_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset_link_prediction = pd.read_csv('output2.csv')\n",
    "print(dataset_link_prediction)\n",
    "\n",
    "'''\n",
    "dataset_ok = pd.read_csv('bello.csv')\n",
    "print(dataset_link_prediction)\n",
    "#print(dataset_ok)\n",
    "\n",
    "\n",
    "generi = set()\n",
    "with open('output2.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        s=line[3].replace(\"[\",\"\")\n",
    "        s=s.replace(\"]\",\"\")\n",
    "        s=s.replace(\"'\",\"\")\n",
    "        genres = s.split(\",\")\n",
    "        for genre in genres:\n",
    "            if len(genre) > 0 and genre[0] == \" \":\n",
    "                genre = genre[1:]\n",
    "            generi.add(genre)\n",
    "\n",
    "for genere in generi:\n",
    "    dataset_link_prediction[genere] = 0\n",
    "\n",
    "print(dataset_link_prediction)\n",
    "\n",
    "riga = -1\n",
    "with open('output2.csv', 'r') as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        if line[0] != 'paese':\n",
    "            riga = riga+1\n",
    "            s=line[3].replace(\"[\",\"\")\n",
    "            s=s.replace(\"]\",\"\")\n",
    "            s=s.replace(\"'\",\"\")\n",
    "            genres = s.split(\",\")\n",
    "            for genre in genres:\n",
    "                if len(genre) > 0 and genre[0] == \" \":\n",
    "                    genre = genre[1:]\n",
    "                dataset_link_prediction.loc[riga,genre] = 1\n",
    "\n",
    "X = dataset_link_prediction.iloc[:, 4:] #feature matrix\n",
    "y = dataset_link_prediction['paese'] # label\n",
    "\n",
    "#print(dataset_link_prediction.loc[1,'art rock'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train_minmax, y_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "y_predicted_lr = clf_logreg.predict(X_test_minmax)\n",
    "\n",
    "print(classification_report(y_test,y_predicted_lr))\n",
    "\n",
    "print(accuracy_score(y_test, y_predicted_lr))\n",
    "#print(len(set(y_test) - set(y_predicted_lr)))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bebd42-c36d-473e-90fb-2256d58836d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae23add-2571-49e5-ab37-06f49a03e373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
