{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione del grafo relativo alla classifica global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Credenziali per utilizzare le api della libreria spotipy\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))\n",
    "\n",
    "#Il file global.csv contiene un link alla classifica top 50 di ognuno dei 72 paesi interessati e alla classifica top 50 globale, oltre a delle informazioni sulla latidudine e longitudine dei paesi\n",
    "countries = list()\n",
    "with open('global.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        countries.append(row)\n",
    "\n",
    "dataset = list()\n",
    "\n",
    "#scorro tutti i paesi\n",
    "for country in countries:\n",
    "\n",
    "    #ottengo la playlist spotify associata al link\n",
    "    playlist = spotify.playlist(country[\"Link\"])\n",
    "    #ed estraggo tutte le sue canzoni\n",
    "    songs = spotify.playlist_items(playlist[\"id\"]) \n",
    "\n",
    "    aux = set()\n",
    "\n",
    "    #il set aux contiene l'ISRC di ogni traccia della playlist\n",
    "    for i in range (len(songs[\"items\"])):\n",
    "        aux.add(songs[\"items\"][i][\"track\"][\"external_ids\"][\"isrc\"])\n",
    "    \n",
    "    dataset.append(aux)\n",
    "\n",
    "n = len(dataset)\n",
    "\n",
    "'''centrality = {}\n",
    "for x in range (1,n) : \n",
    "        affinity = len(dataset[0].intersection(dataset[x]))\n",
    "        centrality[country[x][\"Name\"]] = affinity\n",
    "\n",
    "#print(centrality)\n",
    "\n",
    "centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "header = ['Paese', 'Centralità']\n",
    "with open('global-centrality.csv', 'w+', newline='', encoding='utf-16') as file:\n",
    "    #writer = csv.DictWriter(file,fieldnames=[\"Paese\",\"Centralità\"])\n",
    "    writer = csv.writer(file)\n",
    "    #scrive Paese Centralità nel file csv come intestazione\n",
    "    writer.writerow(header)\n",
    "    #scrive id affiancato da nome nel file\n",
    "    for i in range (len(centrality)) :\n",
    "        writer.writerow(centrality[i])'''\n",
    "\n",
    "#Il grafo\n",
    "grafo = nx.Graph()\n",
    "\n",
    "#Aggiungo un nodo al grafo per ogni paese interessato, insieme alle informazioni sulla sua latitudine e longitudine (questo sarà utile per usare un plug-in in Gephi che mi sistema i nodi su una cartina geografica)\n",
    "for i in range (1,len(countries)) :\n",
    "        grafo.add_node(i,label=countries[i][\"Name\"],latitudine=float(countries[i][\"latitudine\"]),longitudine=float(countries[i][\"longitudine\"]))\n",
    "\n",
    "#considero ogni coppia di paesi\n",
    "for x in range (1,n) : \n",
    "    for y in range (x+1,n) :\n",
    "        #calcolo l'affinità tra i due paesi\n",
    "        affinity = len(dataset[x].intersection(dataset[y]))\n",
    "\n",
    "        #aggiungo l'arco corrispondente al livello di affinità tra i due paesi se questa non è nulla\n",
    "        if affinity :\n",
    "            grafo.add_edge(x,y,weight=affinity)\n",
    "\n",
    "#infine, salvo il grafo in formato gexf e pkl\n",
    "nx.write_gexf(grafo,'global15.gexf')\n",
    "with open('global15.pkl', 'wb') as f:\n",
    "    pickle.dump(grafo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione del grafo relativo alla classifica viral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Credenziali per utilizzare le api della libreria spotipy\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))\n",
    "\n",
    "#Il file global.csv contiene un link alla classifica viral 50 di ognuno dei 72 paesi interessati e alla classifica viral 50 globale, oltre a delle informazioni sulla latidudine e longitudine dei paesi\n",
    "countries = list()\n",
    "with open('viral.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        countries.append(row)\n",
    "\n",
    "dataset = list()\n",
    "\n",
    "#scorro tutti i paesi\n",
    "for country in countries:\n",
    "\n",
    "    #ottengo la playlist spotify associata al link\n",
    "    playlist = spotify.playlist(country[\"Link\"])\n",
    "    #ed estraggo tutte le sue canzoni\n",
    "    songs = spotify.playlist_items(playlist[\"id\"]) \n",
    "\n",
    "    aux = set()\n",
    "\n",
    "    #il set aux contiene l'ISRC di ogni traccia della playlist\n",
    "    for i in range (len(songs[\"items\"])):\n",
    "        aux.add(songs[\"items\"][i][\"track\"][\"external_ids\"][\"isrc\"])\n",
    "    \n",
    "    dataset.append(aux)\n",
    "\n",
    "n = len(dataset)\n",
    "\n",
    "'''centrality = {}\n",
    "for x in range (1,n) : \n",
    "        affinity = len(dataset[0].intersection(dataset[x]))\n",
    "        centrality[country[x][\"Name\"]] = affinity\n",
    "\n",
    "#print(centrality)\n",
    "\n",
    "centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "header = ['Paese', 'Centralità']\n",
    "with open('global-centrality.csv', 'w+', newline='', encoding='utf-16') as file:\n",
    "    #writer = csv.DictWriter(file,fieldnames=[\"Paese\",\"Centralità\"])\n",
    "    writer = csv.writer(file)\n",
    "    #scrive Paese Centralità nel file csv come intestazione\n",
    "    writer.writerow(header)\n",
    "    #scrive id affiancato da nome nel file\n",
    "    for i in range (len(centrality)) :\n",
    "        writer.writerow(centrality[i])'''\n",
    "\n",
    "#Il grafo\n",
    "grafo = nx.Graph()\n",
    "\n",
    "#Aggiungo un nodo al grafo per ogni paese interessato, insieme alle informazioni sulla sua latitudine e longitudine (questo sarà utile per usare un plug-in in Gephi che mi sistema i nodi su una cartina geografica)\n",
    "for i in range (1,len(countries)) :\n",
    "        grafo.add_node(i,label=countries[i][\"Name\"],latitudine=float(countries[i][\"latitudine\"]),longitudine=float(countries[i][\"longitudine\"]))\n",
    "\n",
    "#considero ogni coppia di paesi\n",
    "for x in range (1,n) : \n",
    "    for y in range (x+1,n) :\n",
    "        #calcolo l'affinità tra i due paesi\n",
    "        affinity = len(dataset[x].intersection(dataset[y]))\n",
    "\n",
    "        #aggiungo l'arco corrispondente al livello di affinità tra i due paesi se questa non è nulla\n",
    "        if affinity :\n",
    "            grafo.add_edge(x,y,weight=affinity)\n",
    "\n",
    "#infine, salvo il grafo in formato gexf e pkl\n",
    "nx.write_gexf(grafo,'viral15.gexf')\n",
    "with open('viral15.pkl', 'wb') as f:\n",
    "    pickle.dump(grafo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione del grafo dei generi global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Credenziali per usare le api della libreria spotipy\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))\n",
    "\n",
    "#Il file global.csv contiene un link alla classifica viral 50 di ognuno dei 72 paesi interessati e alla classifica global 50 globale, oltre a delle informazioni sulla latidudine e longitudine dei paesi\n",
    "countries = list()\n",
    "with open('global.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        countries.append(row)\n",
    "\n",
    "#la lista dei generi, che conterrà dei set corrispondenti ai generi degli artisti che hanno fatto una canzone\n",
    "dataset = list()\n",
    "\n",
    "#scorro tutti i paesi\n",
    "for country in countries:\n",
    "    \n",
    "    #ottengo la playlist associata al link\n",
    "    playlist = spotify.playlist(country[\"Link\"])\n",
    "    #e ne ottengo tutte le canzoni\n",
    "    songs = spotify.playlist_items(playlist[\"id\"])\n",
    "    #print(len(songs))\n",
    "    aux = set()\n",
    "    \n",
    "    #scorro tutte le canzoni ottenute\n",
    "    for i in range (len(songs[\"items\"])):\n",
    "        #siccome alcuni artisti non hanno associato un genere, se si prova comunque ad ottenerlo viene sollevata un'eccezione. Per questo racchiudo il codice in un blocco try/catch e, nel caso in cui venisse sollevata, continuo con la prossima canzone\n",
    "        try: \n",
    "            #ottengo i generi dell'artista/artisti che hanno fatto la canzone\n",
    "            genres = spotify.artist(songs[\"items\"][i][\"track\"][\"artists\"][i][\"id\"])['genres']\n",
    "            #e li aggiungo tutti nel set aux\n",
    "            for genre in genres:\n",
    "                aux.add(genre)\n",
    "            #aggiungo tutti i generi degli artisti che hanno fatto una canzone nel dataset\n",
    "            dataset.append(aux)\n",
    "        except:\n",
    "            continue   \n",
    "#print(dataset)\n",
    "\n",
    "grafo = nx.Graph()\n",
    "\n",
    "#scorro tutti i generi\n",
    "for genres in dataset:\n",
    "    #e considero tutti i generi di un set dentro alla lista per costruire il grafo\n",
    "    for genre1 in genres:\n",
    "        for genre2 in genres:\n",
    "            grafo.add_node(genre1)\n",
    "            if genre1 != genre2 and not grafo.has_edge(genre2, genre1):\n",
    "                grafo.add_edge(genre1, genre2)\n",
    "#salvo il grafo in formato gexf e pkl\n",
    "nx.write_gexf(grafo, 'global_genres15.gexf')\n",
    "with open('global_genres15.pkl', 'wb') as f:\n",
    "    pickle.dump(grafo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione del grafo relativo ai generi viral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#Credenziali per usare le api della libreria spotipy\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))\n",
    "\n",
    "#Il file viral.csv contiene un link alla classifica viral 50 di ognuno dei 72 paesi interessati e alla classifica viral 50 globale, oltre a delle informazioni sulla latidudine e longitudine dei paesi\n",
    "countries = list()\n",
    "with open('viral.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        countries.append(row)\n",
    "\n",
    "#la lista dei generi, che conterrà dei set corrispondenti ai generi degli artisti che hanno fatto una canzone\n",
    "dataset = list()\n",
    "\n",
    "#scorro tutti i paesi\n",
    "for country in countries:\n",
    "    \n",
    "    #ottengo la playlist associata al link\n",
    "    playlist = spotify.playlist(country[\"Link\"])\n",
    "    #e ne ottengo tutte le canzoni\n",
    "    songs = spotify.playlist_items(playlist[\"id\"])\n",
    "    #print(len(songs))\n",
    "    aux = set()\n",
    "    \n",
    "    #scorro tutte le canzoni ottenute\n",
    "    for i in range (len(songs[\"items\"])):\n",
    "        #siccome alcuni artisti non hanno associato un genere, se si prova comunque ad ottenerlo viene sollevata un'eccezione. Per questo racchiudo il codice in un blocco try/catch e, nel caso in cui venisse sollevata, continuo con la prossima canzone\n",
    "        try: \n",
    "            #ottengo i generi dell'artista/artisti che hanno fatto la canzone\n",
    "            genres = spotify.artist(songs[\"items\"][i][\"track\"][\"artists\"][i][\"id\"])['genres']\n",
    "            #e li aggiungo tutti nel set aux\n",
    "            for genre in genres:\n",
    "                aux.add(genre)\n",
    "            #aggiungo tutti i generi degli artisti che hanno fatto una canzone nel dataset\n",
    "            dataset.append(aux)\n",
    "        except:\n",
    "            continue   \n",
    "#print(dataset)\n",
    "\n",
    "grafo = nx.Graph()\n",
    "\n",
    "#scorro tutti i generi\n",
    "for genres in dataset:\n",
    "    #e considero tutti i generi di un set dentro alla lista per costruire il grafo\n",
    "    for genre1 in genres:\n",
    "        for genre2 in genres:\n",
    "            grafo.add_node(genre1)\n",
    "            if genre1 != genre2 and not grafo.has_edge(genre2, genre1):\n",
    "                grafo.add_edge(genre1, genre2)\n",
    "#salvo il grafo in formato gexf e pkl\n",
    "nx.write_gexf(grafo, 'viral_genres15.gexf')\n",
    "with open('viral_genres15.pkl', 'wb') as f:\n",
    "    pickle.dump(grafo, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costruzione dei dataset contenenti le prime 10 canzoni delle playlist top e viral 50 globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "import networkx as nx\n",
    "import csv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "#funzione di utilità\n",
    "def list_toString(lista):\n",
    "    aux = \"\"\n",
    "    \n",
    "    for el in lista:\n",
    "        aux += el + \", \"\n",
    "    return aux[:-2]\n",
    "\n",
    "#credenziali per usare le api della libreria spotipy\n",
    "spotify = spotipy.Spotify(client_credentials_manager=SpotifyClientCredentials(client_id=\"85aa8b30835e45a3b99623b2797df916\",client_secret=\"ecb8aa6ad9d7431db74fb99af51dec93\"))\n",
    "\n",
    "#aggiungo tutti i link contenuti nel file global.csv\n",
    "global_countries = list()\n",
    "with open('global.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        global_countries.append(row)\n",
    "        break\n",
    "\n",
    "#stessa cosa per il file viral.csv\n",
    "viral_countries = list()\n",
    "with open('viral.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        viral_countries.append(row)\n",
    "        break\n",
    "\n",
    "aux = {}\n",
    "aux2 = {}\n",
    "\n",
    "#prendo il link della playlist top 50 global\n",
    "playlist = spotify.playlist(global_countries[0][\"Link\"])\n",
    "#e ne ricavo l'id\n",
    "songs = spotify.playlist_items(playlist[\"id\"])\n",
    "\n",
    "#considero le prime 10 canzoni della classifica top 50 globale           \n",
    "for i in range (10):\n",
    "    #estraggo isrc, uri e nome della canzone\n",
    "    isrc = songs[\"items\"][i][\"track\"][\"external_ids\"][\"isrc\"]\n",
    "    track_uri = songs[\"items\"][i][\"track\"][\"uri\"]\n",
    "    track_name = songs[\"items\"][i][\"track\"][\"name\"]\n",
    "\n",
    "    #lista degli artisti che hanno fatto la canzone\n",
    "    artist_name = list()\n",
    "    #aggiungo tutti gli artisti che hanno fatto una canzone\n",
    "    for j in range(len(songs[\"items\"][i][\"track\"][\"artists\"])):\n",
    "        artist_name.append(songs[\"items\"][i][\"track\"][\"artists\"][j][\"name\"])\n",
    "    names = list_toString(artist_name)\n",
    "    album = spotify.album(songs[\"items\"][i][\"track\"][\"album\"][\"external_urls\"][\"spotify\"])\n",
    "    data = album[\"release_date\"]\n",
    "    #aggiungo isrc, uri, titolo, artista/i e data di pubblicazione come info da salvare nel dataset    \n",
    "    aux[i] = {\"isrc\":isrc,\"uri\":track_uri,\"titolo\":track_name,\"artista\":names,\"pubblicazione\":data}\n",
    "\n",
    "\n",
    "#prendo il link della playlist top 50 viral\n",
    "playlist = spotify.playlist(viral_countries[0][\"Link\"])\n",
    "#dal link estraggo l'id della playlist\n",
    "songs = spotify.playlist_items(playlist[\"id\"]) \n",
    "\n",
    "#e il procedimento è il medesimo fatto prima per la classifica top 50 global\n",
    "for i in range (10):\n",
    "    isrc = songs[\"items\"][i][\"track\"][\"external_ids\"][\"isrc\"]\n",
    "\n",
    "    track_uri = songs[\"items\"][i][\"track\"][\"uri\"]\n",
    "    track_name = songs[\"items\"][i][\"track\"][\"name\"]\n",
    "\n",
    "    artist_name = list()\n",
    "    for j in range(len(songs[\"items\"][i][\"track\"][\"artists\"])):\n",
    "        artist_name.append(songs[\"items\"][i][\"track\"][\"artists\"][j][\"name\"])\n",
    "    names = list_toString(artist_name)\n",
    "    album = spotify.album(songs[\"items\"][i][\"track\"][\"album\"][\"external_urls\"][\"spotify\"])\n",
    "    data = album[\"release_date\"]\n",
    "    \n",
    "    aux2[i] = {\"isrc\":isrc,\"uri\":track_uri,\"titolo\":track_name,\"artista\":names,\"pubblicazione\":data}\n",
    "\n",
    "#salvo le info ricavate sulle prime 10 canzoni della classifica top 50 global in un csv\n",
    "with open('15-global.csv', 'w+', newline='', encoding='utf-16') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=[\"isrc\",\"uri\",\"titolo\",\"artista\",\"pubblicazione\"])\n",
    "    writer.writeheader()\n",
    "    for i in range (10):\n",
    "        writer.writerow(aux[i])\n",
    "\n",
    "#salvo le info ricavate sulle prime 10 canzoni della classifica top 50 viral in un csv\n",
    "with open('15-viral.csv', 'w+', newline='', encoding='utf-16') as file:\n",
    "    writer = csv.DictWriter(file,fieldnames=[\"isrc\",\"uri\",\"titolo\",\"artista\",\"pubblicazione\"])\n",
    "    writer.writeheader()\n",
    "    for i in range (10) :\n",
    "        writer.writerow(aux2[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
